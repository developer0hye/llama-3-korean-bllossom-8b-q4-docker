# llama-3-korean-bllossom-8b-q4-docker
8GB GPU로 8B 모델 추론을 추구하면 안되는걸까
